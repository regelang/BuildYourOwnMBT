/// ================================================================================
/// æ­å–œä½ å·²ç»å®Œæˆäº†Identifierçš„è¯æ³•åˆ†æï¼Œç°åœ¨æˆ‘ä»¬æ¥å®Œæˆå…³é”®å­—çš„è¯æ³•åˆ†æã€‚
///
/// å…¶å®éå¸¸ç®€å•ï¼Œåªéœ€è¦åœ¨Identifierçš„åŸºç¡€ä¸Šï¼Œå¢åŠ å¯¹å…³é”®å­—çš„åˆ¤æ–­å³å¯ã€‚
///
/// å½“ä½ è·å¾—ç¬¬ä¸€ä¸ªIdentifierä¹‹åï¼Œå…ˆåˆ«æ€¥ç€æŠŠå®ƒå˜æˆLoweræˆ–è€…Upperè¿”å›ï¼Œ
/// è€Œæ˜¯å…ˆæ£€æŸ¥å®ƒæ˜¯ä¸æ˜¯å…³é”®å­—ï¼Œå¦‚æœæ˜¯ï¼Œå°±è¿”å›å¯¹åº”çš„Keyword
/// å¦åˆ™å†æ ¹æ®é¦–å­—æ¯å¤§å°å†™è¿”å›Loweræˆ–è€…Upperã€‚
///
/// å¦‚ä½•åˆ¤æ–­ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯ä¸æ˜¯å…³é”®å­—å‘¢ï¼Ÿ
///
/// ä½ å¯ä»¥ä½¿ç”¨matchè¯­æ³•ï¼š
///
/// ```moonbit no test
/// let ident : String = ...
/// match ident {
///   "fn" => Fn
///   "let" => Let
///   ...
/// }
/// ```
///
/// æˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥å£°æ˜ä¸€ä¸ªmap:
///
/// ```moonbit no test
/// let keywords : Map[String, Keyword] = {
///   "fn" : Fn,
///   "let" : Let,
///   ...
/// }
/// ```
///
/// ç°åœ¨ç»§ç»­ä¿®æ”¹`lexer/lexer.mbt`æ–‡ä»¶ï¼Œå®Œæˆ`tokenze`å‡½æ•°å§ã€‚
///
/// åœ¨ä½ å®ç°å®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨moon testå‘½ä»¤æ¥è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼š
///
/// æˆ–è€…ç”¨ä¸‹é¢çš„å‘½ä»¤æ¥å•ç‹¬è¿è¡Œå½“å‰æµ‹è¯•ï¼š
///
/// ```
/// moon test -p lexer -f tokenize_keyword_test.mbt
/// ```
///
/// ç¥ä½ æˆåŠŸï¼ğŸš€
/// ================================================================================

///|
test "Tokenize Keyword" {
  let code =
    #|fn let mut if else struct return _
  let tokens = tokenize(code)
  assert_true(tokens.length() is 9)
  assert_true(tokens[0].kind is Keyword(Fn))
  assert_true(tokens[1].kind is Keyword(Let))
  assert_true(tokens[2].kind is Keyword(Mut))
  assert_true(tokens[3].kind is Keyword(If))
  assert_true(tokens[4].kind is Keyword(Else))
  assert_true(tokens[5].kind is Keyword(Struct))
  assert_true(tokens[6].kind is Keyword(Return))
  assert_true(tokens[7].kind is Wildcard)
  assert_true(tokens[8].kind is EOF)
}
