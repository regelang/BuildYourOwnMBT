/// ================================================================================
/// # ğŸŒŸ ç¬¬ä¸€æŒ‘æˆ˜ï¼šè¯æ³•åˆ†æå™¨ (Lexer)
///
/// æ¬¢è¿æ¥åˆ° MiniMoonBit ç¼–è¯‘å™¨çš„ç¬¬ä¸€ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š**è¯æ³•åˆ†æï¼ˆLexingï¼‰**ã€‚
/// è¯æ³•åˆ†ææ˜¯ç¼–è¯‘å™¨ç†è§£æºä»£ç çš„â€œç¬¬ä¸€æ­¥â€ï¼Œå®ƒå°†åŸå§‹çš„æ–‡æœ¬æµè½¬åŒ–ä¸ºä¸€ä¸ªTokenåºåˆ—ã€‚
///
/// ---
///
/// ## ä»€ä¹ˆæ˜¯è¯æ³•åˆ†æï¼Ÿ
///
/// è¯æ³•åˆ†æå™¨ï¼ˆLexer æˆ– Scannerï¼‰çš„ä»»åŠ¡ï¼Œå°±æ˜¯å°†ä¸€ä¸²æºä»£ç å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºä¸€ä¸ªæœ‰æ„ä¹‰çš„**Token åºåˆ—**ã€‚
///
/// ä¾‹å¦‚ï¼Œå¯¹äºä¸€è¡Œ MoonBit ä»£ç ï¼š
///
/// ```
/// let x : Int = 42 ;
/// ```
///
/// è¯æ³•åˆ†æå™¨ä¼šå°†å…¶åˆ†è§£æˆä»¥ä¸‹ç»“æ„åŒ–çš„ Token åºåˆ—ï¼š
///
/// ```
/// (Keyword Let)    // å…³é”®å­— 'let'
/// (Lower "x")      // å°å†™æ ‡è¯†ç¬¦ 'x'
/// (Symbol ":")     // ç¬¦å· ':'
/// (Upper "Int")    // å¤§å†™æ ‡è¯†ç¬¦ 'Int' (é€šå¸¸è¡¨ç¤ºç±»å‹)
/// (Operator "=")   // è¿ç®—ç¬¦ '='
/// (Integer 42)     // æ•´æ•°å¸¸é‡ '42'
/// (Symbol ";")     // ç¬¦å· ';'
/// ```
///
/// æ¢è¨€ä¹‹ï¼Œæˆ‘ä»¬æ­¤é˜¶æ®µçš„ç›®æ ‡ï¼Œå°±æ˜¯å®ç°è¿™ä¸ªè½¬æ¢å‡½æ•°ï¼š
///
/// ```moonbit no test
/// tokenize: (String) -> Array[Token]
/// ```
///
/// ## ğŸ’¡ å®ç°æ€è·¯ï¼šé€ä¸ªå­—ç¬¦çš„æ‰«æå†’é™©
///
/// æˆ‘ä»¬çš„åŸºæœ¬ç­–ç•¥æ˜¯ï¼š**çŠ¶æ€é©±åŠ¨çš„é€å­—ç¬¦æ‰«æ**ã€‚
///
/// 1.  **è·³è¿‡ç©ºç™½ï¼š** ä»å·¦åˆ°å³æ‰«æï¼Œé‡åˆ°ç©ºæ ¼ã€æ¢è¡Œç¬¦ç­‰ç©ºç™½å­—ç¬¦æ—¶ï¼Œç›´æ¥è·³è¿‡ã€‚
/// 2.  **è¯†åˆ«è¾¹ç•Œï¼š** å½“é‡åˆ°ä¸€ä¸ªæœ‰æ„ä¹‰çš„å­—ç¬¦ï¼ˆå¦‚å­—æ¯ã€æ•°å­—æˆ–ç¬¦å·ï¼‰æ—¶ï¼Œæˆ‘ä»¬å¼€å§‹ä¸€ä¸ª Token çš„æå–è¿‡ç¨‹ã€‚
/// 3.  **è´ªå©ªåŒ¹é…ï¼š** ä¾‹å¦‚ï¼Œå¦‚æœé‡åˆ° `l`ï¼Œæˆ‘ä»¬è´ªå©ªåœ°ç»§ç»­æ‰«æï¼Œç›´åˆ°é‡åˆ°éå­—æ¯ã€éæ•°å­—æˆ–éä¸‹åˆ’çº¿çš„å­—ç¬¦ï¼ˆä¾‹å¦‚ç©ºæ ¼ï¼‰ã€‚æ‰«æåˆ°äº† `let`ã€‚
/// 4.  **Token åŒ–ï¼š** æ ¹æ®å®Œæ•´çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ `let`ï¼‰ï¼Œåˆ¤æ–­å®ƒæ˜¯ä¸€ä¸ª**å…³é”®å­—**ã€**æ ‡è¯†ç¬¦**ã€è¿˜æ˜¯**æ“ä½œç¬¦**ç­‰ï¼Œå¹¶å°è£…ä¸ºç›¸åº”çš„ `Token` ç±»å‹ã€‚
/// 5.  **å¾ªç¯å¾€å¤ï¼š** é‡å¤ä»¥ä¸Šè¿‡ç¨‹ï¼Œç›´åˆ°æ•´ä¸ªæºä»£ç å­—ç¬¦ä¸²æ‰«æå®Œæ¯•ã€‚
///
/// ---
///
/// ## ğŸ¯ ä½ çš„ä»»åŠ¡
///
/// è¯·ä¿®æ”¹ `lexer/lexer.mbt` æ–‡ä»¶ï¼Œå®ç° `tokenize` å‡½æ•°ã€‚
/// `lexer/lexer.mbt` ä¸­å·²ä¸ºä½ å®šä¹‰äº† `Token` ç±»å‹å’Œ `tokenize` å‡½æ•°ç­¾åã€‚
///
/// åœ¨ä½ å®ç°å®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨moon testå‘½ä»¤æ¥è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼š
///
/// æˆ–è€…ç”¨ä¸‹é¢çš„å‘½ä»¤æ¥å•ç‹¬è¿è¡Œå½“å‰æµ‹è¯•ï¼š
///
/// ```
/// moon test -p lexer -f tokenize_ident_test.mbt
/// ```
///
/// ## ğŸ› ï¸ å…³é”®å·¥å…·ä¸ MoonBit ç‰¹æ€§ï¼ˆåŠ©ä½ ä¸€è‡‚ä¹‹åŠ›ï¼‰
///
/// MoonBit æä¾›äº†å¼ºå¤§çš„åŸç”Ÿç‰¹æ€§ï¼Œèƒ½è®©ä½ çš„è¯æ³•åˆ†æå®ç°æ›´åŠ ç®€æ´å’Œä¼˜é›…ï¼š
///
/// ### 1. StringViewï¼šé«˜æ•ˆçš„å­—ç¬¦ä¸²åˆ‡ç‰‡
///
/// `String` ä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„å­—ç¬¦ä¸²ã€‚è€Œ `StringView`ï¼ˆé€šè¿‡ `s[:]` è·å¾—ï¼‰ä»£è¡¨å­—ç¬¦ä¸²çš„**è§†å›¾æˆ–å­ä¸²**ã€‚
///
/// ä¾‹å¦‚ï¼Œ`let s = "hello world"`ã€‚`s[0:5]` æ˜¯ä¸€ä¸ª `StringView`ï¼Œè¡¨ç¤º `"hello"`ã€‚
/// ä½¿ç”¨ `StringView` å¯ä»¥é¿å…é¢‘ç¹å¤åˆ¶å­—ç¬¦ä¸²ï¼Œæé«˜æ•ˆç‡ã€‚
///
/// ### 2. å¼ºå¤§çš„æ¨¡å¼åŒ¹é…ï¼ˆPattern Matchingï¼‰
///
/// MoonBit å…è®¸ä½ å¯¹ `StringView` ä½¿ç”¨å¼ºå¤§çš„ç»“æ„åŒ–æ¨¡å¼åŒ¹é…ï¼Œè¿™åœ¨æ‰«ææ—¶éå¸¸æœ‰ç”¨ï¼š
///
/// * **åŒ¹é…å•ä¸ªå­—ç¬¦å¼€å¤´ï¼š**
///     ```moonbit no test
///     let s: StringView = ...
///     // æ£€æŸ¥æ˜¯å¦ä»¥å­—ç¬¦ 'h' å¼€å¤´
///     if s is ['h', ..] {
///         // æ˜¯ä»¥ 'h' å¼€å¤´
///     }
///     ```
///
/// * **åŒ¹é…å­å­—ç¬¦ä¸²å¼€å¤´ï¼š**
///     ```moonbit not test
///     // æ£€æŸ¥æ˜¯å¦ä»¥å­ä¸² "let" å¼€å¤´
///     if s is [.."let", ..] {
///         // æ˜¯ä»¥ "let" å¼€å¤´
///     }
///     ```
///
/// * **åŒ¹é…å­—ç¬¦èŒƒå›´ï¼š** ç”¨äºè¯†åˆ«æ•°å­—ã€å­—æ¯ç­‰ã€‚
///     ```moonbit no test
///     // æ£€æŸ¥æ˜¯å¦ä»¥å°å†™å­—æ¯å¼€å¤´
///     if s is ['a'..='z', ..] {
///         // æ˜¯å°å†™å­—æ¯å¼€å¤´
///     }
///     ```
///
/// ### 3. `loop` è¯­æ³•ï¼šç®€æ´çš„è¿­ä»£æ‰«æ
///
/// MoonBit çš„ `loop` æ˜¯ä¸€ç§ç‹¬ç‰¹çš„å¾ªç¯ç»“æ„ï¼Œå®ƒé€šè¿‡**æ¨¡å¼åŒ¹é…**æ¥æ§åˆ¶è¿­ä»£ï¼Œéå¸¸é€‚åˆè¯æ³•åˆ†æä¸­çš„â€œæŒç»­æ‰«æç›´åˆ°...â€ã€‚
///
/// **ç¤ºä¾‹ï¼šæ‰«æå¹¶è·³è¿‡æ‰€æœ‰ç©ºç™½å­—ç¬¦**
///
/// å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª `StringView` `s`ï¼Œæˆ‘ä»¬æƒ³è·³è¿‡æ‰€æœ‰ç©ºæ ¼ (`' '`) å’Œæ¢è¡Œ (`'\n'`)ï¼š
///
/// ```moonbit
/// let s: StringView = ...
/// let rest_s = loop s { // loop çš„è¿”å›å€¼æ˜¯æœ€ç»ˆåŒ¹é…åˆ°çš„ StringView
///     [' ' | '\n', ..rest] => continue rest // å¦‚æœæ˜¯ç©ºç™½ç¬¦ï¼Œè·³è¿‡å¹¶ç»§ç»­å¾ªç¯å‰©ä¸‹çš„éƒ¨åˆ† (rest)
///     _ => break s // é‡åˆ°ç¬¬ä¸€ä¸ªéç©ºç™½ç¬¦ï¼Œè·³å‡ºå¾ªç¯ï¼Œè¿”å›å½“å‰å‰©ä¸‹çš„ s
/// }
/// // ç°åœ¨ rest_s æŒ‡å‘äº†ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„å­—ç¬¦
/// ```
///
/// ### 4. EOF (æ–‡ä»¶ç»“æŸæ ‡è®°)
///
/// ğŸ“Œ **é‡è¦æé†’ï¼š** è¯æ³•åˆ†æçš„æœ€ç»ˆç»“æœï¼Œåœ¨æ‰€æœ‰æœ‰æ•ˆ Token ä¹‹åï¼Œå¿…é¡»åŒ…å«ä¸€ä¸ªç‰¹æ®Šçš„ `EOF` (End Of File) Tokenã€‚
///
/// è¿™å¯¹æˆ‘ä»¬åç»­çš„**è¯­æ³•åˆ†æå™¨**éå¸¸å…³é”®ï¼Œå®ƒç”¨ä½œç»“æŸæ ‡è®°ï¼Œå¸®åŠ©è¯­æ³•åˆ†æå™¨çŸ¥é“æºä»£ç æµå·²å…¨éƒ¨å¤„ç†å®Œæ¯•ã€‚
///
/// **ç¥ä½ æˆåŠŸï¼è®©æˆ‘ä»¬ä¸€èµ·å¼€å§‹æ„å»ºç¼–è¯‘å™¨çš„ç¬¬ä¸€å—åŸºçŸ³å§ï¼**
/// ================================================================================

///|
test "Tokenize Identifiers - 1" {
  let code =
    #|myStruct my_var anotherVar _privateVar
  let tokens = tokenize(code)
  assert_true(tokens.length() is 5)
  assert_true(tokens[0].kind is Lower("myStruct"))
  assert_true(tokens[1].kind is Lower("my_var"))
  assert_true(tokens[2].kind is Lower("anotherVar"))
  assert_true(tokens[3].kind is Lower("_privateVar"))
  assert_true(tokens[4].kind is EOF)
}

///|
test "Tokenize Identifiers - 2" {
  let code =
    #|fnx let_var mutp iffy else_ match1 structc enum2
  let tokens = tokenize(code)
  assert_true(tokens.length() is 9)
  assert_true(tokens[0].kind is Lower("fnx"))
  assert_true(tokens[1].kind is Lower("let_var"))
  assert_true(tokens[2].kind is Lower("mutp"))
  assert_true(tokens[3].kind is Lower("iffy"))
  assert_true(tokens[4].kind is Lower("else_"))
  assert_true(tokens[5].kind is Lower("match1"))
  assert_true(tokens[6].kind is Lower("structc"))
  assert_true(tokens[7].kind is Lower("enum2"))
  assert_true(tokens[8].kind is EOF)
}

///|
test "Tokenize Identifiers - 3" {
  let code =
    #|Int Unit Bool Double DoubeList
  let tokens = tokenize(code)
  assert_true(tokens.length() is 6)
  assert_true(tokens[0].kind is Upper("Int"))
  assert_true(tokens[1].kind is Upper("Unit"))
  assert_true(tokens[2].kind is Upper("Bool"))
  assert_true(tokens[3].kind is Upper("Double"))
  assert_true(tokens[4].kind is Upper("DoubeList"))
  assert_true(tokens[5].kind is EOF)
}
